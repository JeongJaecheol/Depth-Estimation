{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import FlowNet\n",
    "from dataset import Scene_Flow_disparity\n",
    "\n",
    "dataset = Scene_Flow_disparity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.python.keras.preprocessing.image import array_to_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_check = FlowNet(\n",
    "    img_height = 540,\n",
    "    img_width = 960, \n",
    "    img_depth = 3, \n",
    "    learning_rate = 0.1**4)\n",
    "\n",
    "net_check = model_check.inference('simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_left_x = []\n",
    "train_right_x = []\n",
    "train_y = []\n",
    "\n",
    "itersave = 796\n",
    "iteration = 0\n",
    "for dir_ in dataset.data_paths:\n",
    "    if dataset.data(dir_) is not None:\n",
    "        iteration += 1\n",
    "        left_image, right_image, ground_truth = dataset.data(dir_,\n",
    "                                                             (model_check.model_in_height, model_check.model_in_width),\n",
    "                                                             (model_check.model_out_height, model_check.model_out_width))\n",
    "        train_left_x.append(left_image)\n",
    "        train_right_x.append(right_image)\n",
    "        train_y.append(ground_truth)\n",
    "        print(dir_)\n",
    "\n",
    "    if iteration >= 100:\n",
    "        net_check.load_weights('../weight/FlowNetSimple_Weight/senflow_dataset_weight/flownetSimple_for_depth({0}th).hdf5'.format(itersave))\n",
    "        for i in range(0, 5):\n",
    "            #n = random.randrange(1,81)\n",
    "            n = i\n",
    "            prediction = net_check.predict([np.array(train_left_x)[n:n+1,:], np.array(train_right_x)[n:n+1,:]], batch_size=1)\n",
    "            fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "            ax0.imshow(np.array(train_y)[n,:,:,0])\n",
    "            ax1.imshow(prediction[0,:,:,0])\n",
    "            plt.show()\n",
    "            EPE = np.mean(np.sum(np.abs(np.array(train_y)[n,:,:,0] - prediction[0,:,:,0]), axis=-1))\n",
    "            print(EPE)\n",
    "            fig.savefig('{0}png'.format(i+1))\n",
    "            prediction_img = array_to_img(prediction[0,:])\n",
    "            prediction_img.save('prediction({0}th){1}_epe_{2}.png'.format(itersave, i+1, EPE))\n",
    "                                \n",
    "        train_left_x = []\n",
    "        train_right_x = []\n",
    "        train_y = []\n",
    "        iteration = 0\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_check = FlowNet(\n",
    "    img_height = 370 * 2,\n",
    "    img_width = 427 * 2, \n",
    "    img_depth = 3, \n",
    "    learning_rate = 0.1**4)\n",
    "\n",
    "net_check = model_check.inference('simple')\n",
    "\n",
    "itersave = 796\n",
    "net_check.load_weights('../weight/FlowNetSimple_Weight/senflow_dataset_weight/flownetSimple_for_depth({0}th).hdf5'.format(itersave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_img = load_img(path = \"./data/ETRI_test/aloe/big_view1.png\", grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "r_img = load_img(path = \"./data/ETRI_test/aloe/big_view5.png\", grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "\n",
    "left_image = img_to_array(l_img)\n",
    "right_image = img_to_array(r_img)\n",
    "\n",
    "prediction = net_check.predict([left_image[np.newaxis,:], right_image[np.newaxis,:]], batch_size=1)\n",
    "\n",
    "prediction_img = array_to_img(prediction[0,:])\n",
    "prediction_img.save('prediction_view1.png'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_check = FlowNet(\n",
    "    img_height = 288 * 2,\n",
    "    img_width = 384 * 2, \n",
    "    img_depth = 3, \n",
    "    learning_rate = 0.1**4)\n",
    "\n",
    "net_check = model_check.inference('simple')\n",
    "\n",
    "itersave = 796\n",
    "net_check.load_weights('../weight/FlowNetSimple_Weight/senflow_dataset_weight/flownetSimple_for_depth({0}th).hdf5'.format(itersave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_img = load_img(path = \"./data/ETRI_test/tsukuba/big_tsukuba_left_color.bmp\", grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "r_img = load_img(path = \"./data/ETRI_test/tsukuba/big_tsukuba_right_color.bmp\", grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "\n",
    "left_image = img_to_array(l_img)\n",
    "right_image = img_to_array(r_img)\n",
    "\n",
    "prediction = net_check.predict([left_image[np.newaxis,:], right_image[np.newaxis,:]], batch_size=1)\n",
    "\n",
    "prediction_img = array_to_img(prediction[0,:])\n",
    "prediction_img.save('result_tsukuba_left_color.png'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_check = FlowNet(\n",
    "    img_height = 1080,\n",
    "    img_width = 1920, \n",
    "    img_depth = 3, \n",
    "    learning_rate = 0.1**4)\n",
    "\n",
    "net_check = model_check.inference('simple')\n",
    "\n",
    "itersave = 796\n",
    "net_check.load_weights('../weight/FlowNetSimple_Weight/senflow_dataset_weight/flownetSimple_for_depth({0}th).hdf5'.format(itersave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, 2):\n",
    "    raw = n * 5\n",
    "    for i in range(0, 4):\n",
    "        left_number = raw + i\n",
    "        right_number = raw + i + 1\n",
    "        l_img = load_img(path = \"./data/ETRI_test/CG_Testset1_20180711/Image/image_0{0}.png\".format(left_number), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "        r_img = load_img(path = \"./data/ETRI_test/CG_Testset1_20180711/Image/image_0{0}.png\".format(right_number), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "\n",
    "        left_image = img_to_array(l_img)\n",
    "        right_image = img_to_array(r_img)\n",
    "\n",
    "        prediction = net_check.predict([left_image[np.newaxis,:], right_image[np.newaxis,:]], batch_size=1)\n",
    "\n",
    "        prediction_img = array_to_img(prediction[0,:])\n",
    "        prediction_img.save('result_image_0{0}.png'.format(left_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_check = FlowNet(\n",
    "    img_height = 1080,\n",
    "    img_width = 1920, \n",
    "    img_depth = 3, \n",
    "    learning_rate = 0.1**4)\n",
    "\n",
    "net_check = model_check.inference('simple')\n",
    "\n",
    "itersave = 796\n",
    "net_check.load_weights('../weight/FlowNetSimple_Weight/senflow_dataset_weight/flownetSimple_for_depth({0}th).hdf5'.format(itersave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 2):\n",
    "    CAM_NUM = i * 5 +1\n",
    "    for j in range(0, 2):\n",
    "        l_img = load_img(path = \"./data/ETRI_test/ETRI_chef_0_100/Cam0{0}_0{1}00.bmp\".format(CAM_NUM, j), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "        r_img = load_img(path = \"./data/ETRI_test/ETRI_chef_0_100/Cam0{0}_0{1}00.bmp\".format(CAM_NUM - 1, j), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "\n",
    "        left_image = img_to_array(l_img)\n",
    "        right_image = img_to_array(r_img)\n",
    "\n",
    "        prediction = net_check.predict([left_image[np.newaxis,:], right_image[np.newaxis,:]], batch_size=1)\n",
    "\n",
    "        prediction_img = array_to_img(prediction[0,:])\n",
    "        prediction_img.save('Cam0{0}_0{1}00.png'.format(CAM_NUM, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_check = FlowNet(\n",
    "    img_height = 1088,\n",
    "    img_width = 2048, \n",
    "    img_depth = 3, \n",
    "    learning_rate = 0.1**4)\n",
    "\n",
    "net_check = model_check.inference('simple')\n",
    "\n",
    "itersave = 796\n",
    "net_check.load_weights('../weight/FlowNetSimple_Weight/senflow_dataset_weight/flownetSimple_for_depth({0}th).hdf5'.format(itersave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, 4):\n",
    "    raw = n * 4\n",
    "    for i in range(0, 3):\n",
    "        left_number = raw + i\n",
    "        right_number = raw + i + 1\n",
    "        l_img = load_img(path = \"./data/ETRI_test/TechnicolorPainter_pr_100_#00_#15/TechnicolorPainter_pr_100_#{:0=2}.png\".format(left_number), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "        r_img = load_img(path = \"./data/ETRI_test/TechnicolorPainter_pr_100_#00_#15/TechnicolorPainter_pr_100_#{:0=2}.png\".format(right_number), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "\n",
    "        left_image = img_to_array(l_img)\n",
    "        right_image = img_to_array(r_img)\n",
    "\n",
    "        prediction = net_check.predict([left_image[np.newaxis,:], right_image[np.newaxis,:]], batch_size=1)\n",
    "\n",
    "        prediction_img = array_to_img(prediction[0,:])\n",
    "        prediction_img.save('result_image_{:0=2}.png'.format(left_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_check = FlowNet(\n",
    "    img_height = 544,\n",
    "    img_width = 1024, \n",
    "    img_depth = 3, \n",
    "    learning_rate = 0.1**4)\n",
    "\n",
    "net_check = model_check.inference('simple')\n",
    "\n",
    "itersave = 796\n",
    "net_check.load_weights('../weight/FlowNetSimple_Weight/senflow_dataset_weight/flownetSimple_for_depth({0}th).hdf5'.format(itersave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, 4):\n",
    "    raw = n * 4\n",
    "    for i in range(0, 3):\n",
    "        left_number = raw + i\n",
    "        right_number = raw + i + 1\n",
    "        l_img_tmp = load_img(path = \"./data/ETRI_test/TechnicolorPainter_pr_100_#00_#15/TechnicolorPainter_pr_100_#{:0=2}.png\".format(left_number), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "        r_img_tmp = load_img(path = \"./data/ETRI_test/TechnicolorPainter_pr_100_#00_#15/TechnicolorPainter_pr_100_#{:0=2}.png\".format(right_number), grayscale = False, target_size = (model_check.model_in_height, model_check.model_in_width), interpolation = 'bicubic')\n",
    "\n",
    "        l_img = l_img_tmp.resize((model_check.model_in_width, model_check.model_in_height), Image.BILINEAR)\n",
    "        r_img = r_img_tmp.resize((model_check.model_in_width, model_check.model_in_height), Image.BILINEAR)\n",
    "        \n",
    "        left_image = img_to_array(l_img)\n",
    "        right_image = img_to_array(r_img)\n",
    "\n",
    "        prediction = net_check.predict([left_image[np.newaxis,:], right_image[np.newaxis,:]], batch_size=1)\n",
    "\n",
    "        prediction_img = array_to_img(prediction[0,:])\n",
    "        prediction_img.save('result_image_{:0=2}.png'.format(left_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
