{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras.api.keras.backend as K\n",
    "from tensorflow.python.keras.utils import multi_gpu_model\n",
    "from tensorflow.python.keras.models import Model, Sequential, model_from_config\n",
    "from tensorflow.python.keras.layers import Input , Reshape, Permute, Lambda\n",
    "from tensorflow.python.keras.layers import Add, add, multiply\n",
    "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.python.keras.layers import Conv3D, Conv3DTranspose\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, BatchNormalization\n",
    "from tensorflow.python.keras.layers import concatenate, MaxPooling2D\n",
    "from tensorflow.python.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "def CostVolume(inputs, max_d):\n",
    "        left_tensor, right_tensor = inputs\n",
    "        shape = right_tensor.shape\n",
    "        right_tensor = K.spatial_2d_padding(right_tensor, padding=((0, 0), (max_d, 0)))\n",
    "        disparity_costs = []\n",
    "        for d in reversed(range(max_d)):\n",
    "            left_tensor_slice = left_tensor\n",
    "            right_tensor_slice = tf.slice(right_tensor, begin = [0, 0, d, 0], size = [-1, -1, shape[2], -1])\n",
    "            cost = K.concatenate([left_tensor_slice, right_tensor_slice], axis = 3)\n",
    "            disparity_costs.append(cost)\n",
    "        cost_volume = K.stack(disparity_costs, axis = 1)\n",
    "        return cost_volume\n",
    "    \n",
    "def SoftArgMax(inputs, height, width, disp_range):\n",
    "        print('1')\n",
    "        tmp = tf.squeeze(inputs, squeeze_dims=-1)\n",
    "        print('2')\n",
    "        softmax = tf.nn.softmax(-tmp)\n",
    "        print('3')\n",
    "        disp_mat = tf.constant(list(map(lambda x: x, range(1, 192+1, 1))), shape=(192, 512, 960))\n",
    "        disp_mat = tf.cast(disp_mat, tf.float32)\n",
    "        print('4')\n",
    "        result = tf.multiply(softmax, disp_mat)\n",
    "        print('5')\n",
    "        result = tf.reduce_sum(result, axis = 1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (512, 960, 3)\n",
    "img = Input(shape = input_shape, dtype = \"float32\", name='l_img')\n",
    "layer1 = Conv2D(32, (5, 5), (2, 2), padding='same', activation='relu', name='layer1')(img)\n",
    "layer2 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer2')(layer1)\n",
    "layer3 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer3')(layer2)        \n",
    "short_cut1 = add([layer1, layer3])\n",
    "\n",
    "layer4 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer4')(short_cut1)\n",
    "layer5 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer5')(layer4)\n",
    "short_cut2 = add([layer4, layer5])\n",
    "layer6 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer6')(short_cut2)\n",
    "layer7 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer7')(layer6)\n",
    "short_cut3 = add([layer6, layer7])\n",
    "layer8 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer8')(short_cut3)\n",
    "layer9 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer9')(layer8)\n",
    "short_cut4 = add([layer8, layer9])\n",
    "layer10 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer10')(short_cut4)\n",
    "layer11 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer11')(layer10)\n",
    "short_cut5 = add([layer10, layer11])\n",
    "layer12 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer12')(short_cut5)\n",
    "layer13 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer13')(layer12)\n",
    "short_cut6 = add([layer12, layer13])\n",
    "layer14 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer14')(short_cut6)\n",
    "layer15 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer15')(layer14)\n",
    "short_cut7 = add([layer14, layer15])\n",
    "layer16 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer16')(short_cut7)\n",
    "layer17 = Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu', name='layer17')(layer16)\n",
    "short_cut8 = add([layer16, layer17])\n",
    "       \n",
    "layer18 = Conv2D(32, (3, 3), (1, 1), padding='same', name='layer18')(short_cut8)\n",
    "\n",
    "#net = Model(inputs = img, outputs = layer18)\n",
    "#net.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unifeatures = [layer18, layer18]   \n",
    "cv_l = Lambda(CostVolume, arguments = {'max_d':(int)(192 / 2)}, name='CostVolume_left')(unifeatures)\n",
    "\n",
    "layer19 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(cv_l)\n",
    "layer20 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer19)\n",
    "layer21 = Conv3D(64, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(layer20)\n",
    "layer22 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer21)\n",
    "layer23 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer22)\n",
    "layer24 = Conv3D(64, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(layer23)\n",
    "layer25 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer24)\n",
    "layer26 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer25)\n",
    "layer27 = Conv3D(64, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(layer26)\n",
    "layer28 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer27)\n",
    "layer29 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer28)\n",
    "layer30 = Conv3D(64, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(layer29)\n",
    "layer31 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer30)\n",
    "layer32 = Conv3D(32, (3, 3, 3), (1, 1, 1), padding='same', activation='relu')(layer31)\n",
    "\n",
    "layer33 = Conv3DTranspose(64, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(layer32)\n",
    "short_cut1 = add([layer27, layer33])\n",
    "layer34 = Conv3DTranspose(64, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(short_cut1)\n",
    "short_cut2 = add([layer24, layer34])\n",
    "layer35 = Conv3DTranspose(64, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(short_cut2)\n",
    "short_cut3 = add([layer21, layer35])\n",
    "layer36 = Conv3DTranspose(32, (3, 3, 3), (2, 2, 2), padding='same', activation='relu')(short_cut3)\n",
    "short_cut4 = add([layer20, layer36])\n",
    "layer37 = Conv3DTranspose(1, (3, 3, 3), (2, 2, 2), padding='same')(short_cut4)\n",
    "print('############################')\n",
    "disp_map = Lambda(SoftArgMax, \n",
    "                  arguments = {'height':512, 'width':960, 'disp_range':192}, \n",
    "                 )(layer37)\n",
    "\n",
    "net = Model(inputs = img, outputs = disp_map)\n",
    "net.summary() \n",
    "\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "\n",
    "plot_model(net, to_file='test_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#list(map(lambda x: x, range(1, 192+1, 1)))\n",
    "disp_mat = tf.constant(list(map(lambda x: x, range(1, 192+1, 1))), shape=(192, 512, 960))\n",
    "sess = tf.Session()\n",
    "result = sess.run(disp_mat)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
